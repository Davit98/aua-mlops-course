{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9702015-a7fa-4ac1-83b6-e89d54a64041",
   "metadata": {},
   "source": [
    "# AUA, DS 229 – MLOps\n",
    "### Week 4 – Tests in Machine Learning\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90176738-e72f-46fc-9314-27552946da6f",
   "metadata": {},
   "source": [
    "<center><img src=\"images/unit_integration_tests.jpeg\" width=\"600\" height=\"600\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495471d2-869c-4f28-bc62-e5384937e578",
   "metadata": {},
   "source": [
    "<p><b>Unit tests</b></p> A unit test is the smallest and simplest form of software testing. These tests are employed to assess a separable unit of software, such as a class or function, for correctness independent of the larger software system that contains the unit. Unit tests are also employed as a form of specification to ensure that a function or module exactly performs the behavior required by the system. Unit tests are commonly used to introduce test-driven development concepts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a14953-94c5-42aa-b2ec-cf5029afdd99",
   "metadata": {},
   "source": [
    "<p><b>Integration tests</b></p> Software components that pass individual unit tests are assembled into larger components. Engineers then run an integration test on an assembled component to verify that it functions correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741fe543-5c49-4f9d-b78c-7241def160e0",
   "metadata": {},
   "source": [
    "<p><b>System tests</b></p> A system test is the largest scale test that engineers run for an undeployed system. All modules belonging to a specific component, such as a server that passed integration tests, are assembled into the system. Then the engineer tests the end-to-end functionality of the system. System tests come in many different flavors:\n",
    "\n",
    "- Smoke tests, in which engineers test very simple but critical behavior, are among the simplest type of system tests. Smoke tests are also known as sanity testing, and serve to short-circuit additional and more expensive testing.\n",
    "\n",
    "- Performance tests, once basic correctness is established via a smoke test, a common next step is to write another variant of a system test to ensure that the performance of the system stays acceptable over the duration of its lifecycle. Because response times for dependencies or resource requirements may change dramatically during the course of development, a system needs to be tested to make sure that it doesn’t become incrementally slower without anyone noticing (before it gets released to users). For example, a given program may evolve to need 32 GB of memory when it formerly only needed 8 GB, or a 10 ms response time might turn into 50 ms, and then into 100 ms. A performance test ensures that over time, a system doesn’t degrade or become too expensive.\n",
    "\n",
    "- Regression tests are conducted to prevent bugs from sneaking back into the codebase. Regression tests can be analogized to a gallery of rogue bugs that historically caused the system to fail or produce incorrect results. By documenting these bugs as tests at the system or integration level, engineers refactoring the codebase can be sure that they don’t accidentally introduce bugs that they’ve already invested time and effort to eliminate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749cebc2-afe3-4f29-83e8-df6c0f38473d",
   "metadata": {},
   "source": [
    "**Some benefits of writing unit tests:**\n",
    "- You can catch bugs earlier in the development cycle which is important since if bugs appear in released code, it may inconvenience end-users and potentially cause major losses in a business sense.\n",
    "- You can make changes to your code with more confidence since any upgrades or refactoring you do will break the system if they are done incorrectly (and will work accordingly if done correctly)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fc09da-81a9-4503-a676-bdac97faaa16",
   "metadata": {},
   "source": [
    "## Part 1: Introduction to [unittest](https://docs.python.org/3/library/unittest.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e27ef51-750b-4509-87c7-27835bf6fd06",
   "metadata": {},
   "source": [
    "The basic building blocks of unit testing are **test cases** — single scenarios that must be set up and checked for correctness. In unittest, test cases are represented by **unittest.TestCase** instances. To make your own test cases you must write subclasses of TestCase. The testing code of a TestCase instance should be entirely self contained, such that it can be run either in isolation or in arbitrary combination with any number of other test cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5521a8-6e44-4c49-b367-b73fce6e4948",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b064c4e8-a34b-43bf-8ab1-16e7a219f3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rectangle:\n",
    "    \n",
    "    def __init__(self, width, height):\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "    \n",
    "    def get_area(self):\n",
    "        return self.width * self.height\n",
    "    \n",
    "    def get_perimeter(self):\n",
    "        return 2 * (self.width+self.height)\n",
    "    \n",
    "    def get_wrong_perimeter(self):\n",
    "        return self.width + self.height\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"[Rectangle with width={self.width} and height={self.height}]\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0b262d-73a0-4594-b5ea-f821cefaf1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = Rectangle(4, 5)\n",
    "print(\"The area of\", rec, \"is:\", rec.get_area())\n",
    "print(\"The perimeter of\", rec, \"is:\", rec.get_perimeter())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eeb9ece-5455-4922-834a-1215c83c5774",
   "metadata": {},
   "source": [
    "Let's start writing some tests for our rectangle!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5743e7-f4a9-4ca7-a153-8b1b704e15a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RectangleTests(unittest.TestCase):\n",
    "\n",
    "    @classmethod\n",
    "    def setUpClass(cls):\n",
    "        cls.rectangles = [Rectangle(w, h) for (w, h) in [(1, 2), (4, 8), (10, 15)]]\n",
    "\n",
    "    # def setUp(self):\n",
    "    #     self.rectangles = [Rectangle(w, h) for (w, h) in [(1, 2), (4, 8), (10, 15)]]\n",
    "\n",
    "    def test_area(self):\n",
    "        for rec in self.rectangles:\n",
    "            area = rec.get_area()\n",
    "            ground_truth = rec.width * rec.height\n",
    "            self.assertEqual(area, ground_truth, f\"{rec}'s area calculation is wrong, expected {ground_truth} but got {area}.\")\n",
    "    \n",
    "    def test_perimeter(self):\n",
    "        for rec in self.rectangles:\n",
    "            perimeter = rec.get_perimeter()\n",
    "            ground_truth = 2 * (rec.width+rec.height)\n",
    "            self.assertEqual(perimeter, ground_truth, f\"{rec}'s perimeter calculation is wrong, expected {ground_truth} but got {perimeter}.\")\n",
    "            \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    unittest.main(argv=[''], verbosity=2, exit=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbe9c72-af81-4272-a724-cb1797c154fb",
   "metadata": {},
   "source": [
    "**setUp**: Method called to prepare the test fixture. This is called immediately before calling the test method.  \n",
    "**setUpClass**: A class method called before tests in an individual class are run. setUpClass is called with the class as the only argument and must be decorated as a `classmethod()`.\n",
    "\n",
    "The main difference between **setUpClass** and **setUp** is that the former is called only once and that is before all the tests, while **setUp** is called immediately before each and every test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd084bba-cdb7-4ba8-a2b2-868d68d51c9c",
   "metadata": {},
   "source": [
    "Now let's test **get_wrong_perimeter** method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b827a20-c94f-4537-98a3-250c74fd0424",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RectangleTests(unittest.TestCase):\n",
    "\n",
    "    @classmethod\n",
    "    def setUpClass(cls):\n",
    "        cls.rectangles = [Rectangle(w, h) for (w, h) in [(1, 2), (4, 8), (10, 15)]]\n",
    "        \n",
    "    def test_wrong_perimeter(self):\n",
    "        for rec in self.rectangles:\n",
    "            perimeter = rec.get_wrong_perimeter()\n",
    "            ground_truth = 2 * (rec.width+rec.height)\n",
    "            self.assertEqual(perimeter, ground_truth, f\"{rec}'s perimeter calculation is wrong, expected {ground_truth} but got {perimeter}.\")\n",
    "            \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    unittest.main(argv=[''], verbosity=2, exit=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207302b2-5f6c-4823-bfe7-4b4b7dddb226",
   "metadata": {},
   "source": [
    "When there are very small differences among your tests, for instance some parameters, unittest allows you to distinguish them inside the body of a test method using the **subTest()** context manager. Without using a subtest, *execution would stop after the first failure*, and the error would be less easy to diagnose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84386ae7-8cdd-4f59-b045-082da03ee91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RectangleTests(unittest.TestCase):\n",
    "\n",
    "    @classmethod\n",
    "    def setUpClass(cls):\n",
    "        cls.rectangles = [Rectangle(w, h) for (w, h) in [(1, 2), (4, 8), (10, 15)]]\n",
    "        \n",
    "    def test_wrong_perimeter(self):\n",
    "        for rec in self.rectangles:\n",
    "            with self.subTest():  # I can make you distinguish your tests!\n",
    "                perimeter = rec.get_wrong_perimeter()\n",
    "                ground_truth = 2 * (rec.width+rec.height)\n",
    "                self.assertEqual(perimeter, ground_truth, f\"{rec}'s perimeter calculation is wrong, expected {ground_truth} but got {perimeter}.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    unittest.main(argv=[''], verbosity=2, exit=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b107053f-4466-46b1-ba40-b83d322a8ec5",
   "metadata": {},
   "source": [
    "The TestCase class provides several assert methods to check for and report failures. The following table lists the most commonly used methods:\n",
    "\n",
    "<center><img src=\"images/asserts.png\" width=\"500\" height=\"500\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364dba13-a248-419a-9b2f-04551f4db540",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    With <b>pytest</b> we can run parametrized tests and get rid of the <b>for</b> loop in testing methods. Let's talk about that in the next class.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb304071-259a-4200-bb2b-642f456de6d7",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da54ba0-25fa-4f3b-9a11-fc0cb57d513a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Action</b>:\n",
    "    Restart the notebook to escape from running tests from the previous problem.\n",
    "</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0867c47f-3a7c-437a-9d09-16daa19b2f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326ece82-3e3a-47d8-8cfe-f49bc8555778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a list of even numbers in the given range. Note that both bounds are inclusive.\n",
    "def get_even_numbers(left=1, right=10, nums=[]):\n",
    "    start = left if left % 2 == 0 else left + 1\n",
    "    for n in range(start, right+1, 2):\n",
    "        nums.append(n)\n",
    "    return nums\n",
    "\n",
    "\n",
    "# result = get_even_numbers(1, 6)\n",
    "# result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cc8f01-7ead-4a27-b1ca-5944c3e27657",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvenNumbersTests(unittest.TestCase):\n",
    "\n",
    "    @classmethod\n",
    "    def setUpClass(cls):\n",
    "        cls.ranges = [(1, 2), (4, 8), (11, 15)]\n",
    "        cls.ground_truths = [[2], [4, 6, 8], [12, 14]]\n",
    "        \n",
    "    def test_even_numbers(self):\n",
    "        for idx, (left, right) in enumerate(self.ranges):\n",
    "            with self.subTest():\n",
    "                even_numbers = get_even_numbers(left, right)\n",
    "                ground_truth = self.ground_truths[idx]\n",
    "                self.assertListEqual(even_numbers, ground_truth)\n",
    "            \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    unittest.main(argv=[''], verbosity=2, exit=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb44c94-294f-43b0-9c0e-66bdef3006a0",
   "metadata": {},
   "source": [
    "#### Let's understand the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2874cee2-fa19-4bbb-84ea-04cc73b05eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_even_numbers(left=1, right=10, nums=[]):\n",
    "    start = left if left % 2 == 0 else left + 1\n",
    "    for n in range(start, right+1, 2):\n",
    "        nums.append(n)\n",
    "    return nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6fbbea-d757-44da-9d7f-1af0f4ffd054",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = get_even_numbers(1, 6)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b02aec-8b7d-4b96-89ae-98766b08b280",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = get_even_numbers(20, 24)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161a0fa7-146d-43ca-84a9-8778060aa581",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>Default arguments are evaluated once at module load time. This may cause problems if the argument is a mutable object such as a list or a dictionary. If the function modifies the object (e.g., by appending an item to a list), the default value is modified.</b>\n",
    "    \n",
    "Recall that a mutable object is an object whose state can be modified after it is defined.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998db6b0-b80e-4ac8-9b8f-06e4cb1359d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_even_numbers(left=1, right=10, nums=[]):\n",
    "    start = left if left % 2 == 0 else left + 1\n",
    "    for n in range(start, right+1, 2):\n",
    "        nums += [n]  # Will this help?\n",
    "    return nums\n",
    "\n",
    "\n",
    "result = get_even_numbers(1, 6)\n",
    "result = get_even_numbers(20, 24)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373aca02-1077-481c-b23b-d568d3487026",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_even_numbers(left=1, right=10, nums=[]):\n",
    "    start = left if left % 2 == 0 else left + 1\n",
    "    for n in range(start, right+1, 2):\n",
    "        nums = nums + [n]  # But what is the differece?\n",
    "    return nums\n",
    "\n",
    "\n",
    "result = get_even_numbers(1, 6)\n",
    "result = get_even_numbers(20, 24)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8854836-9964-4530-9860-58bdc9dd0b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommended solution!\n",
    "def get_even_numbers(left=1, right=10, nums: list = None):\n",
    "    if nums is None:\n",
    "        nums = []\n",
    "    \n",
    "    start = left if left % 2 == 0 else left + 1\n",
    "    for n in range(start, right+1, 2):\n",
    "        nums.append(n)\n",
    "    return nums\n",
    "\n",
    "\n",
    "result = get_even_numbers(1, 6)\n",
    "result = get_even_numbers(20, 24)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38fc9c5-1d3c-40ed-9a66-e3cac59aa439",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvenNumbersTests(unittest.TestCase):\n",
    "\n",
    "    @classmethod\n",
    "    def setUpClass(cls):\n",
    "        cls.ranges = [(1, 2), (4, 8), (11, 15)]\n",
    "        cls.ground_truths = [[2], [4, 6, 8], [12, 14]]\n",
    "        \n",
    "    def test_even_numbers(self):\n",
    "        for idx, (left, right) in enumerate(self.ranges):\n",
    "            with self.subTest(left=left, right=right):\n",
    "                even_numbers = get_even_numbers(left, right)\n",
    "                ground_truth = self.ground_truths[idx]\n",
    "                self.assertListEqual(even_numbers, ground_truth)\n",
    "            \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    unittest.main(argv=[''], verbosity=2, exit=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3fa7d1-fa7d-4504-89a7-a53af925227f",
   "metadata": {},
   "source": [
    "## Part 2: Running speed tests with [cProfile](https://docs.python.org/3/library/profile.html) and [time](https://docs.python.org/3/library/time.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da7694a-64b9-4b3a-804a-f0a7fffddf90",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Action</b>:\n",
    "    Restart the notebook to escape from running tests from the previous problem.\n",
    "</div> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf615d6-9347-42f7-bea9-0bfae08ece5b",
   "metadata": {},
   "source": [
    "**Problem**: Implement Euclidean distance\n",
    "$$\n",
    "  d(a, b) = \\sqrt{\\sum_{i=1}^{n} (a_i - b_i)^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df231de1-496f-44b2-9fa8-c1d1fd0edd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "import math \n",
    "\n",
    "\n",
    "# Version 1:\n",
    "def simple_euclidean_distance(a, b):\n",
    "    distance = 0.0\n",
    "    for e1, e2 in zip(a, b):\n",
    "        distance += (e1 - e2) ** 2\n",
    "    return math.sqrt(distance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdadfeed-90c1-425f-a949-05e64ed00e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "n_trials = 200\n",
    "length = 200000\n",
    "\n",
    "\n",
    "with cProfile.Profile() as pr:\n",
    "    for _ in range(n_trials):\n",
    "        a, b = np.random.random_sample(size=length), np.random.random_sample(size=length)\n",
    "        _ = simple_euclidean_distance(a, b)\n",
    "\n",
    "pr.print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8046389d-9695-42c0-9d47-c658bb3dc301",
   "metadata": {},
   "source": [
    "<ol>\n",
    "<li><b>ncalls</b> : Shows the number of calls made.</li>\n",
    "<li><b>tottime</b>: Total time taken by the given function. Note that the time made in calls to sub-functions are excluded.</li>\n",
    "<li><b>percall</b>: Total time / No of calls. (remainder is left out)</li>\n",
    "<li><b>cumtime</b>: Unlike tottime, this includes time spent in this and all subfunctions that the higher-level function calls. It is most useful and is accurate for recursive functions.</li>\n",
    "<li>The <b>percall</b> following cumtime is calculated as the quotient of cumtime divided by primitive calls. The primitive calls include all the calls that were not included through recursion.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ce3362-3dae-46b7-8a9b-82d584ba8bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version 2:\n",
    "def numpy_euclidean_distance(a, b):\n",
    "    return np.sqrt(((a-b)**2).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec997065-6c64-4a50-9b55-7295c5aca412",
   "metadata": {},
   "outputs": [],
   "source": [
    "with cProfile.Profile() as pr:\n",
    "    \n",
    "    for _ in range(n_trials):\n",
    "        a, b = np.random.random_sample(size=length), np.random.random_sample(size=length)\n",
    "        _ = numpy_euclidean_distance(a, b)\n",
    "\n",
    "pr.print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bf7f19-48fa-4fd7-8cfa-38af5f4276a3",
   "metadata": {},
   "source": [
    "**NumPy uses vectorized implementations which are much faster and more efficient as compared to for-loops.**   \n",
    "Recall that NumPy’s ND-arrays are homogeneous: an array can only contain data of a single type. For instance, an array can contain 8-bit integers or 32-bit floating point numbers, but not a mix of the two. This is in stark contrast to Python’s lists and tuples, which are entirely unrestricted in the variety of contents they can possess; a given list could simultaneously contain strings, integers, and other objects. This restriction on an array’s contents comes at a great benefit; in “knowing” that an array’s contents are homogeneous in data type, NumPy is able to delegate the task of performing mathematical operations on the array’s contents to optimized, compiled C code. This is a process that is referred to as vectorization. The outcome of this can be a tremendous speedup relative to the analogous computation performed in Python, which must painstakingly check the data type of every one of the items as it iterates over the arrays, since Python typically works with lists with unrestricted contents.\n",
    "\n",
    "[Source: [“Vectorized” Operations: Optimized Computations on NumPy Arrays](https://www.pythonlikeyoumeanit.com/Module3_IntroducingNumpy/VectorizedOperations.html)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7564ceb2-c100-4d27-8b72-de3d81a60dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "class FunctionExecutionSpeedTests(unittest.TestCase):\n",
    "\n",
    "    @classmethod\n",
    "    def setUpClass(cls):\n",
    "        cls.threshold = 1.0  # Execution should take no longer than a second.\n",
    "        cls.data = ((np.random.random_sample(size=length), np.random.random_sample(size=length)) for n_trial in range(10))\n",
    "        \n",
    "    def test_execution_time(self):\n",
    "        start = time.time()\n",
    "        \n",
    "        for (a, b) in self.data:\n",
    "            _ = numpy_euclidean_distance(a, b)\n",
    "            \n",
    "        end = time.time()\n",
    "        duration_in_sec = end - start\n",
    "        self.assertLessEqual(duration_in_sec, self.threshold)\n",
    "        \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    unittest.main(argv=[''], verbosity=2, exit=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0bea95-c29a-476a-a629-c3a2432d4871",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Part 3: An example of running a data engineering test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10485e18-6c73-4662-b97d-a91e3c1ca118",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Action</b>:\n",
    "    Restart the notebook to escape from running tests from the previous problem.\n",
    "</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bb6847-dd1e-4487-9c9f-da8e7b2b8aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import unittest\n",
    "\n",
    "\n",
    "data = [\n",
    "    {\"product_id\": \"p1\", \"count\": 3, \"price\": 20},\n",
    "    {\"product_id\": \"p1\", \"count\": 1, \"price\": 23},\n",
    "    {\"product_id\": \"p2\", \"count\": 1, \"price\": 73},\n",
    "    {\"product_id\": \"p2\", \"count\": 1, \"price\": 34},\n",
    "    {\"product_id\": \"p2\", \"count\": 2, \"price\": 55},\n",
    "    {\"product_id\": \"p3\", \"count\": 1, \"price\": 20},\n",
    "    {\"product_id\": \"p4\", \"count\": 1, \"price\": 71},\n",
    "    {\"product_id\": \"p4\", \"count\": 1, \"price\": 73},\n",
    "    {\"product_id\": \"p4\", \"count\": 5, \"price\": 34},\n",
    "    {\"product_id\": \"p4\", \"count\": 3, \"price\": 55}\n",
    "]\n",
    "\n",
    "\n",
    "dataset = pd.DataFrame(data)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553286b8-619d-42f3-915a-b26e0ae33d29",
   "metadata": {},
   "source": [
    "**Task**  \n",
    "Repeat the `price` as many times as the corresponding `count` value is, form a list of prices (as shown below) and compute median price for each product."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebde98e-28ae-4674-89fb-1a65e2143fee",
   "metadata": {},
   "source": [
    "| product_id | prices |\n",
    "| --- | --- |\n",
    "| p1 | [20, 20, 20, 23] | \n",
    "| p2 | [34, 55, 55, 73] | \n",
    "| p3 | [20] | \n",
    "| p4 | [34, 34, 34, 34, 34, 55, 55, 55, 73] | "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b8e3cb-e871-43db-9371-b19d96709559",
   "metadata": {},
   "source": [
    "#### Solution 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9122665-5a5d-47cd-820e-4a9d59d2c34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Loop over unique product ids.\n",
    "# 2) Select count and price corresponding to a particular product.\n",
    "# 3) Repeat prices by their corresponding counts.\n",
    "# 4) Construct a numpy array and calculate median for a specific product, store the result.\n",
    "# 5) Go to step 2.\n",
    "\n",
    "def solve_with_loop(df):\n",
    "    product2median = {}\n",
    "    for p_id in df[\"product_id\"].unique():\n",
    "        info = df[df[\"product_id\"] == p_id][[\"count\", \"price\"]]\n",
    "        expanded_info = pd.DataFrame(info.values.repeat(info[\"count\"].values, axis=0), columns=[\"count\", \"price\"])\n",
    "        expanded_values = expanded_info[\"price\"].values\n",
    "        product2median[p_id] = np.median(expanded_values)\n",
    "    \n",
    "    result= pd.DataFrame({\"product_id\": product2median.keys(), \"median_price\": product2median.values()})\n",
    "    return result \n",
    "\n",
    "\n",
    "result = solve_with_loop(dataset)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d3e9c7-a9bc-4eb9-b347-e4a2b5de78b8",
   "metadata": {},
   "source": [
    "#### Solution 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89bde5e-287e-45eb-8513-57c88d2e5ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Repeat indices by 'count' number of times.\n",
    "# 2) Select te rows specified by indices (note that if an index is repeated twice, then that row will also be selected twice).\n",
    "# 3) Group by product ids, select price and apply median to it (reset indices as otherwise product_id will be index as a result of groupby). \n",
    "\n",
    "def solve_without_loop(df):\n",
    "    repeated_data = df.loc[df.index.repeat(df[\"count\"])].reset_index(drop=True)\n",
    "    result = repeated_data.groupby(by=\"product_id\")[[\"price\"]].agg(median_price=(\"price\", \"median\")).reset_index()\n",
    "    return result\n",
    "\n",
    "# expanded_data = repeated_data.groupby(by=\"product_id\")[[\"price\"]].agg(list).reset_index()\n",
    "result = solve_without_loop(dataset)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f2c41b-aab4-46b7-87c9-d2b5f5734b0c",
   "metadata": {},
   "source": [
    "#### Write tests for comparing pandas dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82532915-7d22-4668-bebe-0a79f07fb19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.testing import assert_frame_equal\n",
    "\n",
    "\n",
    "class PriceMedianTests(unittest.TestCase):\n",
    "\n",
    "    @classmethod\n",
    "    def setUpClass(cls):\n",
    "        \n",
    "        # Mock data.\n",
    "        data = [\n",
    "            {\"product_id\": \"p1\", \"timestamp\": 1665393218, \"count\": 3, \"price\": 20},\n",
    "            {\"product_id\": \"p1\", \"timestamp\": 11665306219, \"count\": 1, \"price\": 23},\n",
    "            {\"product_id\": \"p2\", \"timestamp\": 1665395718, \"count\": 1, \"price\": 73},\n",
    "            {\"product_id\": \"p2\", \"timestamp\": 1665385218, \"count\": 1, \"price\": 34},\n",
    "            {\"product_id\": \"p2\", \"timestamp\": 1665397658, \"count\": 2, \"price\": 55},\n",
    "            {\"product_id\": \"p3\", \"timestamp\": 1665393218, \"count\": 1, \"price\": 20},\n",
    "            {\"product_id\": \"p4\", \"timestamp\": 1665393218, \"count\": 1, \"price\": 71},\n",
    "            {\"product_id\": \"p4\", \"timestamp\": 1665386548, \"count\": 1, \"price\": 73},\n",
    "            {\"product_id\": \"p4\", \"timestamp\": 1665757648, \"count\": 5, \"price\": 34},\n",
    "            {\"product_id\": \"p4\", \"timestamp\": 11665246539, \"count\": 3, \"price\": 55}\n",
    "        ]\n",
    "        \n",
    "        gr = [\n",
    "            {\"product_id\": \"p1\", \"median_price\": 20.0},\n",
    "            {\"product_id\": \"p2\", \"median_price\": 55.0},\n",
    "            {\"product_id\": \"p3\", \"median_price\": 20.0},\n",
    "            {\"product_id\": \"p4\", \"median_price\": 44.5}\n",
    "        ]\n",
    "\n",
    "        cls.dataset = pd.DataFrame(data)\n",
    "        cls.ground_truth = pd.DataFrame(gr)\n",
    "        \n",
    "    def test_median_price(self):\n",
    "        result = solve_without_loop(self.dataset)\n",
    "        assert_frame_equal(result, self.ground_truth)\n",
    "        \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    unittest.main(argv=[''], verbosity=2, exit=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83a55c4-3911-4908-b97c-b2886390d733",
   "metadata": {},
   "source": [
    "## References\n",
    "- [The ML Test Score: A Rubric for ML Production Readiness and Technical Debt Reduction\n",
    "](https://research.google/pubs/pub46555/)\n",
    "- [Testing for Reliability](https://sre.google/sre-book/testing-reliability/)\n",
    "- [unittest — Unit testing framework](https://docs.python.org/3/library/unittest.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_mlops",
   "language": "python",
   "name": "env_mlops"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
