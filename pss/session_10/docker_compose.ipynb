{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d983f558-83bc-41f2-bc5a-4bc10866f1d5",
   "metadata": {},
   "source": [
    "# AUA, DS 229 – MLOps\n",
    "### Week 12 – Docker Compose in all its beauty\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd3980c-96d6-4589-b7e5-f6809b6a23be",
   "metadata": {
    "tags": []
   },
   "source": [
    "## [PostgreSQL](https://www.postgresql.org/)\n",
    "\n",
    "\n",
    "<center><img src=\"./images/postgresql.png\" width=400 height = 80/></center>\n",
    "\n",
    "PostgreSQL is a popular open-source relational database management system that stores data in a structured way. When you create a database in PostgreSQL, it creates a directory on your system's file system where all the data associated with that database is stored.\n",
    "\n",
    "Within the database directory, PostgreSQL stores the data in files called tables. Each table has a name and consists of rows and columns. The data in each row is stored in a separate file, and the columns are stored as individual fields within each file.\n",
    "\n",
    "The most significant contrast between SQLite and other servers such as MySQL or Postgres is that SQLite is essentially a file which can be accessed with SQL, whereas **Postgres is a server that necessitates interaction**.\n",
    "\n",
    "- **Server-based**: Postgres is typically hosted on cloud servers, such as those provided by Amazon or Google. This allows multiple users or applications to connect to it simultaneously and perform operations. *In contrast, imagine collaborating with someone in another country using a SQLite file. It would be challenging to determine where to store the file and establish a connection for both parties. With a Postgres server, each user can access it using a connection string that includes the IP and Port of the server, enabling them to establish a socket connection to the database*.\n",
    "\n",
    "- **Full text search**: Postgres is capable of storing vector representations of textual data and performing lightning-fast queries on it. This feature is beneficial for various purposes, such as implementing autocomplete search fields on websites and conducting data science projects that involve natural language processing.\n",
    "\n",
    "- **Data types**: Compared to SQLite, Postgres provides a more *extensive range of column data types*. Some examples of column types that are available in Postgres but not SQLite include:\n",
    "    - *JSON*: allows you to store JSON arrays and perform queries on them.\n",
    "    - *MONEY*: simplifies working with time series data, such as stock prices.\n",
    "    - *Date* and *timestamp*: allows you to sort and index data based on dates and times, which is particularly useful for time series data.\n",
    "    - *Inet/cidr*: enables you to store IP addresses, which can be helpful for certain web applications.\n",
    "\n",
    "***\n",
    "Installation guides:\n",
    "- [Windows](https://www.postgresqltutorial.com/postgresql-getting-started/install-postgresql/)\n",
    "- [Linux](https://www.postgresqltutorial.com/postgresql-getting-started/install-postgresql-linux/)\n",
    "- [MacOS](https://www.postgresqltutorial.com/postgresql-getting-started/install-postgresql-macos/)\n",
    "\n",
    "> Set the PATH environment variable as done [here](https://stackoverflow.com/questions/36155219/psql-command-not-found-mac).\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81da6ad7-0597-46aa-b990-08d98bec98e7",
   "metadata": {},
   "source": [
    "### Plan for today:\n",
    "1) Play with PostgreSQL database.\n",
    "2) Introduce `docker-compose`.\n",
    "3) Run 2 services -- a Python API and a PostgreSQL db, where the API must support requests to write/read from the db.\n",
    "4) Is there any dependency? How to handle it with docker?\n",
    "5) Explore the API with swagger-ui. \n",
    "6) What if I cange my code when the containers are still running? Maybe I need to rebuild them..\n",
    "7) A few words about \"Shadow mode deployment\".\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60356f61-58aa-4bd6-8833-b148fd6f03dd",
   "metadata": {},
   "source": [
    "### HTTP request methods\n",
    "\n",
    "**When developing a web application, deciding which HTTP request method (GET, POST, PUT, DELETE, etc.) to use for a particular operation depends on the nature of the operation and the conventions of the HTTP protocol. Here's a general guideline to help you make this decision**:\n",
    "\n",
    "- **GET**: This method should be used when you want to retrieve data from the server. In general, GET requests should not have side effects on the server, meaning they should not change any data or state on the server. For example, when you want to retrieve a webpage, a list of products, or some user information, you would typically use a GET request.\n",
    "\n",
    "- **POST**: This method should be used when you want to create new data on the server. POST requests usually involve submitting a form or uploading a file, and they may modify the state of the server by adding new data to a database or initiating a new process. In general, a POST request should be used when you are creating new data on the server.\n",
    "\n",
    "- **PUT**: This method should be used when you want to update existing data on the server. A PUT request usually involves submitting data to update an existing resource or record. In general, a PUT request should be used when you are modifying an existing resource on the server.\n",
    "\n",
    "- **DELETE**: This method should be used when you want to delete data from the server. A DELETE request usually involves deleting an existing resource or record. In general, a DELETE request should be used when you want to remove an existing resource from the server.\n",
    "\n",
    "In summary, GET requests should be used for retrieving data, POST requests should be used for creating new data, PUT requests should be used for updating existing data, and DELETE requests should be used for deleting existing data. However, it's important to note that these guidelines are not strict rules, and the conventions may vary depending on the specific application and its requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9163d6d9-5f5e-4e62-b011-1f0e6556d728",
   "metadata": {},
   "source": [
    "Now let's connect to PostgreSQl on local machine, create a database, table and query the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71af1f8f-8a39-45d8-8114-7c1216a1f0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64  # For password encryption.\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, MetaData, inspect, Column, Integer, String\n",
    "from sqlalchemy_utils import database_exists, create_database, drop_database\n",
    "from sqlalchemy.orm import declarative_base, sessionmaker, scoped_session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26960f44-74d7-48d5-aa13-785364a981c6",
   "metadata": {},
   "source": [
    "Use te following code to hide your password in code. Although this is not a clever idea (the encription function has openly available inverse), we can use it for its simplicity. \n",
    "\n",
    "```python\n",
    "<ENCODED-PASSWORD> = base64.b64encode(<PASSWORD>).encode(\"utf-8\")\n",
    "<PASSWORD> = base64.b64decode(<ENCODED-PASSWORD>).decode(\"utf-8\")\n",
    "```\n",
    "\n",
    "The current most popular tool for storing sensitive information is [Vault](https://www.vaultproject.io/) which we are not going to cover. Another option is [docker secrets](https://docs.docker.com/engine/swarm/secrets/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b62ea8-829f-4bb7-b542-69988a4f11ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credentials.\n",
    "username = \"postgres\"\n",
    "password = base64.b64decode(\"RGF2JHlhbjNpZDAw\").decode(\"utf-8\")  # Returns a string.\n",
    "hostname = \"localhost\"\n",
    "port = \"5432\"\n",
    "db_name = \"aua_mlops_test_db\"\n",
    "\n",
    "# Constructing URL for PostgreSQL.\n",
    "DB_URL = f\"postgresql://{username}:{password}@{hostname}:{port}/{db_name}\"\n",
    "\n",
    "# Create (if necessary) and connect.\n",
    "engine = create_engine(DB_URL, pool_recycle=3600)\n",
    "if not database_exists(engine.url):\n",
    "    print(\"Creating the database..\", end=\" \")\n",
    "    create_database(engine.url)\n",
    "    print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13ac393-2e02-4a4a-94d7-90ec15545b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the table names.\n",
    "def get_table_names(engine):\n",
    "    metadata = MetaData()\n",
    "    inspector = inspect(engine)\n",
    "    print(\"Registered tables:\", inspector.get_table_names())\n",
    "    \n",
    "\n",
    "get_table_names(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec59cba-6e57-430f-9a02-c3adecff0a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "Base = declarative_base()\n",
    "metadata = Base.metadata\n",
    "\n",
    "\n",
    "class TestTable(Base):\n",
    "    __tablename__ = \"test_table\"\n",
    "    \n",
    "    row_id = Column(Integer, primary_key=True, autoincrement=True)  # Starts from 1.\n",
    "    name = Column(String(100))\n",
    "    age = Column(Integer)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"<TestTable(row_id={self.row_id}, name={self.name}, age={self.age})>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed02cc48-1eb5-4da3-a37a-3b1de2727f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the table(s).\n",
    "metadata.create_all(bind=engine)\n",
    "get_table_names(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b3e6c1-9472-4570-bcf6-116f56dbc03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining session object to run queries.\n",
    "session_factory = sessionmaker(bind=engine)\n",
    "Session = scoped_session(session_factory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28530c29-c12a-4762-a42f-e4d2e29761fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in some data.\n",
    "samples = [\n",
    "    TestTable(name=\"Murzik\", age=65), \n",
    "    TestTable(name=\"Ernesto Parpeci\", age=68),\n",
    "    TestTable(name=\"Voldemort\", age=13)\n",
    "]\n",
    "print(\"An example of a sample:\", samples[0])\n",
    "\n",
    "with Session() as sess:\n",
    "    sess.add_all(samples)\n",
    "    sess.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2bbdc1-b763-4f27-a26a-f6c69ffa6200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data.\n",
    "with Session() as sess:\n",
    "    result = sess.query(TestTable.name, TestTable.age).all()\n",
    "    \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bf5bef-667f-41ea-b17e-460101d9d8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data as pandas DataFrame.\n",
    "with Session() as sess:\n",
    "    data = pd.read_sql_query(sql = sess.query(TestTable.name, TestTable.age).statement,\n",
    "                             con = engine.connect())\n",
    "    \n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1d79c3-1451-470e-a60d-575902c70384",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Action</b>:\n",
    "    <b>Open pgAdmin 4 and visualize the table.\n",
    "</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1039b7a-a753-4f5a-a43e-e77aaaeeca8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the table:\n",
    "engine = create_engine(DB_URL, pool_recycle=3600)\n",
    "TestTable.__table__.drop(bind=engine)\n",
    "get_table_names(engine)\n",
    "\n",
    "# Drop the database:\n",
    "drop_database(DB_URL)\n",
    "if not database_exists(engine.url):\n",
    "    print(\"Successfully dropped the database.\")\n",
    "    \n",
    "engine.dispose()  # Close the connection to the db."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0702b4c9-e546-4c6b-a196-c486c661e6c5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# [Docker Compose](https://docs.docker.com/compose/)\n",
    "\n",
    "<center><img src=\"./images/docker_compose.png\" width=400 height = 80/></center>\n",
    "\n",
    "Docker Compose is a tool that allows you to **define and run multi-container Docker applications**. It is used to manage the configuration and orchestration of multiple Docker containers as a single application, making it easier to deploy and manage complex applications.\n",
    "\n",
    "With Docker Compose, you can define the services that make up your application in a YAML file. Each service can be defined with its own configuration options, including image, environment variables, ports, and volumes. You can also define dependencies between services, so that one service can be started only after another service is running.\n",
    "\n",
    "Once you have defined your application in a Compose file, you can use the `docker-compose` command to start, stop, and manage your containers. Docker Compose will automatically create and manage the necessary containers and networks to run your application, based on the configuration specified in the Compose file.\n",
    "\n",
    "<center><img src=\"./images/docker_compose_arch.png\" width=700 height = 80/></center>\n",
    "\n",
    "[[Image source](https://www.biaudelle.fr/docker-compose/)]\n",
    "\n",
    "A Docker Compose file, usually named `docker-compose.yml`, is written in YAML format and consists of one or more services that define the containers, volumes, and networks that make up an application.\n",
    "\n",
    "- The `version` field specifies the version of the Docker Compose syntax to use. In this example, we are using version 3.8.\n",
    "- The `services` section defines the containers that make up our application. Each service has a name, which is used to refer to it within the Compose file and other Docker commands.\n",
    "- `environment` section in each app is used to set environment variables.\n",
    "- The `volumes` section defines named volumes that can be used by the services.\n",
    "\n",
    "Docker Compose files can be much more complex depending on the needs of the application. However, the basic structure remains the same: define the services that make up the application, configure the containers, volumes, and networks, and specify any dependencies between services.\n",
    "\n",
    "**Commands**:\n",
    "- `docker-compose up`: This command starts the containers defined in the `docker-compose.yml` file. If the containers don't exist, Docker Compose will create them. The `up` command also builds any images that need to be built and attaches the containers to a network.\n",
    "- `docker-compose down`: This command stops and removes the containers defined in the `docker-compose.yml` file. It also removes any volumes and networks associated with the containers.\n",
    "- `docker-compose ps`: This command lists the containers started by Docker Compose, along with their status.\n",
    "- `docker-compose logs`: This command shows the logs of the containers started by Docker Compose. By default, it shows the logs of all containers. You can specify a service name to show only the logs of that service.\n",
    "- `docker-compose build`: This command builds the images for the services defined in the `docker-compose.yml` file.\n",
    "- `docker-compose exec`: This command runs a command inside a running container. You can specify the service name and the command to run. For example, `docker-compose exec web bash` will start a shell inside the web container.\n",
    "- `docker-compose restart`: This command restarts the containers defined in the `docker-compose.yml` file. You can specify a service name to restart only that service."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d5b851-729f-4fae-9fad-1fdb7e569200",
   "metadata": {},
   "source": [
    "### Examine the `docker-compose.yml` file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cb148e-44aa-4d83-a69a-0c369cefe93e",
   "metadata": {},
   "source": [
    "#### app\n",
    "\n",
    "```\n",
    "├── app/\n",
    "│   ├── requirements.txt\n",
    "│   ├── tables.py\n",
    "│   ├── prepare_db.py\n",
    "│   ├── endpoints.py\n",
    "│   ├── swagger.yml.py\n",
    "│   ├── openapi_main.py\n",
    "│   ├── start_service.sh\n",
    "│   └── Dockerfile\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb6cca1-c284-419e-9d49-682e4e1d3fb0",
   "metadata": {},
   "source": [
    "`start_service.sh`\n",
    "\n",
    "```bash\n",
    "#!/bin/bash\n",
    "\n",
    "set -e\n",
    "\n",
    "exec python prepare_db.py &  # Creates a table in the database (runs in the background).\n",
    "exec python openapi_main.py  # Runs the API.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7deb4057-984d-47d9-b3ef-4a904c587e16",
   "metadata": {},
   "source": [
    "**`set -e`**   \n",
    "> `set -e` is a command in a Linux bash script that tells the shell to exit immediately if any command in the script fails (i.e., returns a non-zero exit status).\n",
    "\n",
    "> By default, if a command in a bash script fails, the script will continue running unless you specifically handle the error with an if statement or some other mechanism. However, in some cases, you might want the script to stop immediately if any command fails, to prevent any further damage or unwanted behavior.\n",
    "\n",
    "> In this example, `set -e` is used at the beginning of the script to ensure that any command that fails will cause the script to immediately exit.\n",
    "\n",
    "> Note that `set -e` can be disabled in a specific part of the script by using `set +e`. This can be useful if you want to handle errors in a specific section of the script without exiting the script entirely.\n",
    "\n",
    "> It's generally a good practice to use `set -e` in your bash scripts to ensure that errors are caught early and the script doesn't continue executing with potentially invalid or incomplete data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b441879e-60ae-41da-9ecf-14ceb9450b16",
   "metadata": {},
   "source": [
    "**`exec`**  \n",
    "> In a bash script, `exec` is a command that is used **to replace the current shell process with a new process**. This can be useful in situations where you want to run a new command or script, but you don't want to create a new process for it as done by default.\n",
    "\n",
    "> Note that `exec` can also be used without specifying a command, in which case it will simply replace the current shell process with a new, empty process. This can be useful for cleaning up the environment or resetting the shell state.\n",
    "\n",
    "> Note that if we remove `exec` part from the above commands the result won't change 😊."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2136b6-c131-416f-b23e-6d1c74d36993",
   "metadata": {},
   "source": [
    "**`&`**  \n",
    "> In a bash script, you can run commands in **detached mode** by adding an ampersand (`&`) at the end of the command. **This will run the command in the background, allowing the script to continue executing without waiting for the command to complete.**\n",
    "\n",
    "> Note that when a command is run in detached mode, its output will not be visible in the terminal unless it is redirected to a file or another command. You can redirect the output to a file using the `>` operator or pipe it to another command using the `|` operator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec56f219-341c-419b-a3d6-6c911bbeca1e",
   "metadata": {},
   "source": [
    "#### database\n",
    "\n",
    "```yml\n",
    "version: '3.8'\n",
    "\n",
    "services:\n",
    "\n",
    "  app:\n",
    "    build:\n",
    "      context: ./app\n",
    "      dockerfile: Dockerfile\n",
    "    ports:\n",
    "      - \"8000:8000\"\n",
    "    volumes: \n",
    "      - ./app:/app\n",
    "    depends_on:\n",
    "      database:\n",
    "        condition: service_healthy\n",
    "\n",
    "  database:\n",
    "    image: postgres:15.2-alpine\n",
    "    restart: always\n",
    "    environment:\n",
    "      POSTGRES_USER: docker_db_user\n",
    "      POSTGRES_PASSWORD: the_most_secure_pass\n",
    "      POSTGRES_DB: aua_mlops_test_db\n",
    "    ports:\n",
    "      - \"5454:5432\"\n",
    "    volumes: \n",
    "      - database:/var/lib/postgresql/data\n",
    "    healthcheck:\n",
    "      test: [ \"CMD-SHELL\", \"pg_isready -d $${POSTGRES_DB} -U $${POSTGRES_USER}\"]\n",
    "      interval: 10s\n",
    "      timeout: 5s\n",
    "      retries: 5\n",
    "      \n",
    "volumes:\n",
    "  database:\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d8826d-1ba3-4829-9251-632ef929e053",
   "metadata": {},
   "source": [
    "**Volumes**  \n",
    "> Docker volumes are a way to store persistent data used by Docker containers outside of the container's filesystem. Volumes are created and managed by Docker and can be shared among multiple containers, allowing data to persist even when a container is deleted or recreated.\n",
    "\n",
    "**environment**  \n",
    "> In a Docker Compose file, the `POSTGRES_USER`, `POSTGRES_PASSWORD`, and `POSTGRES_DB` environment variables are used to configure a PostgreSQL container.\n",
    "\n",
    "> `POSTGRES_USER`: This environment variable sets the username for the default PostgreSQL user *postgres*. When you start a PostgreSQL container, this user is created automatically. You can use `POSTGRES_USER` to set a custom username for this user.\n",
    "\n",
    "> `POSTGRES_PASSWORD`: This environment variable sets the password for the postgres user. It's important to set a password for the postgres user to ensure that your database is secure.\n",
    "\n",
    "> `POSTGRES_DB`: This environment variable sets the name of the default database that will be created when the PostgreSQL container starts. By default, the database is named **postgres**, but you can use `POSTGRES_DB` to set a custom name.\n",
    "\n",
    "**`restart: always`**  \n",
    "> In a Docker Compose file, the `restart: always` option for a PostgreSQL service specifies that the container should always be restarted if it stops for any reason (to not try to \"continue\" running). \n",
    "\n",
    "> Generally, if you stop and then start a container, the container will resume running from the point where it was stopped. Any processes that were running inside the container before it was stopped will continue running as if nothing had happened.\n",
    "\n",
    "> This option is particularly useful for services that need to be highly available and should always be running. By using the `restart: always` option, you can ensure that your PostgreSQL service is automatically restarted in case of any unexpected downtime.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0d3533-1016-479f-8862-ef560f4cfcf7",
   "metadata": {},
   "source": [
    "### Networks and dependencies\n",
    "\n",
    "<center><img src=\"./images/bridge_network.png\" width=500 height = 80/></center>\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "When you run `docker-compose up`, Docker Compose creates a network for your services and connects the containers to that network. <b>This allows the containers to communicate with each other using their service names as the hostnames, without the need to expose ports or use external IP addresses</b>.\n",
    "\n",
    "By default, Docker Compose creates a <b>bridge</b> network for your services, and assigns a unique name to the network based on the name of your project. For example, if your project is named **myapp**, the default network name would be <b>myapp_default</b>.\n",
    "</div> \n",
    "    \n",
    "The `depends_on` option in Docker Compose is used **to specify the order in which services should be started or stopped**. It's useful when you have multiple services that depend on each other and need to be started or stopped in a specific order.\n",
    "\n",
    "When you run `docker-compose up`, Compose will start the services in the order specified by `depends_on`. In our case, it will first start the **database** service, and then the **app** service (once the **database** service is up – read the below statement carefully).\n",
    "\n",
    "<mark>**IMPORTANT**</mark>  \n",
    "It's important to note that `depends_on` only **specifies the order in which services should be started or stopped**. **It doesn't wait for the services to be fully available or ready before starting the dependent service**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78720922-9e47-4fc9-8b55-7b36f5c29a0a",
   "metadata": {},
   "source": [
    "<mark>But how to wait for the service to be available/up ?</mark>\n",
    "\n",
    "**In Docker, a health check is a command that a container runs to determine whether or not it is healthy. A healthy container is one that is able to respond to requests and perform its intended function**. A health check is a way for Docker to monitor the status of a container and determine whether or not it needs to be restarted.\n",
    "\n",
    "The `service_healthy` option in Docker Compose is used to wait for a service to be healthy before proceeding with the start-up of dependent services. In our example we have a **app** service that depends on a **database** service. You can define a health check for the **database** service using `healthcheck`, and then use the `service_healthy` option to make sure that the **database** service is healthy before starting the **app** service. This is what we have done in our `docker-compose.yml`.\n",
    "\n",
    "By using health checks and the `service_healthy` option, you can ensure that your services are running correctly before proceeding with the start-up of dependent services.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57488ff5-6e6c-4ee6-b193-c801ec697db3",
   "metadata": {},
   "source": [
    "The `docker-compose --build` command is used to build (or rebuild) the Docker images for services defined in a Docker Compose file. It is useful when you need to make changes to your application's code or dependencies and want to rebuild the Docker images that your services are based on.\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Action</b>:\n",
    "    <b>Open a terminal an run</b>: `docker-compose up --build`\n",
    "</div> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29b7e72-82e0-46ec-9cf4-cd33b5b908eb",
   "metadata": {},
   "source": [
    "1) Visit http://localhost:8000/ui\n",
    "2) Explore the API request methods and play with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fceabf-2c21-4f38-9eda-2c1edafe0f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################\n",
    "########## If you want to connect to the db on container ##########\n",
    "###################################################################\n",
    "\n",
    "### You can use the following credentials to connect to the database\n",
    "### that is running on a container and execute, for example, all\n",
    "### the operations provided in the starting part of this notebook.\n",
    "\n",
    "# username = \"docker_db_user\"\n",
    "# password = \"the_most_secure_pass\"\n",
    "# hostname = \"localhost\"\n",
    "# port = \"5454\"\n",
    "# db_name = \"aua_mlops_test_db\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142d0941-44ee-473d-8134-ae96f97ccb1b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Action</b>:\n",
    "    <b>Connect to the database on container using pgAdmin 4.\n",
    "</div> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29a6fa4-4810-4637-9ced-a1a0a28ce422",
   "metadata": {},
   "source": [
    "<mark>Note</mark> : If you decide to change username or password above (in `docker-compose.yml`) you will first need to remove the volume (`docker volume rm <VOLUME-NAME>`) defined in `docker-compose.yml`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83de0533-aad2-4ba2-8ea2-e816cc749ba8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Shadow mode deployment\n",
    "\n",
    "Shadow mode deployment is a technique used in MLOps (Machine Learning Operations) to validate the performance of a new version of a machine learning model before it is fully deployed to production.\n",
    "\n",
    "In this approach, the new version of the model is deployed in a \"shadow\" mode alongside the current production model. **The shadow model receives the same inputs and produces the same outputs as the current model, but its predictions are not used by the application**.\n",
    "\n",
    "**Instead, the predictions made by the shadow model are compared to those made by the current model to identify any discrepancies. This allows developers to validate the performance of the new model against the current production model, and to make sure that the new model is producing accurate and consistent results**.\n",
    "\n",
    "<center><img src=\"./images/shadow_mode.jpeg\" width=500 height = 100/></center>\n",
    "\n",
    "[[image source](https://christophergs.com/machine%20learning/2019/03/30/deploying-machine-learning-applications-in-shadow-mode/)]\n",
    "\n",
    "Shadow mode deployment is particularly useful when deploying changes to models that have a high impact on business outcomes or user experience, such as models that drive recommendations or predictions for critical business decisions. It helps reduce the risk of unintended consequences and ensures that the new model performs as expected before it is fully deployed to production."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aecb25d6-e8aa-4c30-bd51-541ec7a01811",
   "metadata": {},
   "source": [
    "# References\n",
    "- [SQLAlchemy](https://docs.sqlalchemy.org/en/20/)\n",
    "- [PostgreSQL Engine Configuration](https://docs.sqlalchemy.org/en/20/core/engines.html)\n",
    "- [An example of creating a simple RESTful App using OpenAPI, Flask & Connexions](https://haseebmajid.dev/posts/2019-08-16-creating-a-simple-restful-app-using-openapi-flask-connexions/)\n",
    "- [Communication between docker containers](https://docs.docker.com/compose/networking/)\n",
    "- [Serivce startup control](https://docs.docker.com/compose/startup-order/)\n",
    "- Docker [depends_on](https://docs.docker.com/compose/compose-file/05-services/#depends_on) and [healthcheck](https://docs.docker.com/compose/compose-file/05-services/#healthcheck)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_mlops",
   "language": "python",
   "name": "env_mlops"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
