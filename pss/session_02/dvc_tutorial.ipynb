{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fe1e227-74c3-4060-8fa8-90ef94aff021",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Tutorial: Data Version Control with DVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9e6c98-f875-4bd5-88f4-08ed7ba95715",
   "metadata": {},
   "source": [
    "- [DVC - Installation](https://dvc.org/)\n",
    "- [DVC - Tutorial: Data and Model Versioning](https://dvc.org/doc/use-cases/versioning-data-and-models/tutorial)\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3ff4fd-5f36-4301-a522-5a00c627b5c0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### The 3 axis of change in a Machine Learning application\n",
    "<center><img src=\"images/ml_modeling.png\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875fadd8-5822-40b4-ac74-9fdaf94b53c4",
   "metadata": {},
   "source": [
    "#### <font color='green'>Version contrl system vs Data version system</font>\n",
    "Version control systems help developers manage changes to source code. But data version control, managing changes to **models** and **datasets** isn’t so well established. In a version control system, there’s a central repository of code that represents the current, official state of the project. Developers can make a copy of a project, make some changes, and request that their new version become the official one. Their code is then reviewed and tested before it’s deployed to production. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a90c17-4e6d-4538-b046-ae320b0a69d0",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### <font color='green'>dvc & git</font>\n",
    "Data version control is a set of tools and processes that tries to adapt the version control process to the data world. **DVC is a command-line tool written in Python. It mimics Git commands and workflows to ensure that users can quickly incorporate it into their regular Git practice. DVC is meant to be run alongside Git. In fact, the ```git``` and ```dvc``` commands will often be used in tandem, one after the other. While Git is used to store and version code, DVC does the same for data and model files.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9416b4b3-b273-4b14-ac55-c54baab9bc34",
   "metadata": {},
   "source": [
    "Git can store code locally and also on a hosting service like GitHub, Bitbucket, or GitLab. Likewise, DVC uses a remote repository to store all your data and models. This is the single source of truth, and it can be shared amongst the whole team. You can get a local copy of the remote repository, modify the files, then upload your changes to share with team members. The remote repository can be on the same computer you’re working on, or it can be in the cloud. DVC supports most major cloud providers, including **AWS**, **GCP**, and **Azure**. But you can set up a DVC remote repository on any server and connect it to your laptop. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f1c0af-cfe6-4bef-961d-1a140dc9f5e6",
   "metadata": {},
   "source": [
    "#### <font color='green'>.dvc & .git</font>\n",
    "Running `dvc init` (similar to `git init`) will create a `.dvc` folder that holds configuration information, just like the `.git` folder for Git. In principle, you don’t ever need to open that folder, but you’ll take a peek in this tutorial so you can understand what’s happening under the hood.\n",
    "> Executing `git init` creates a ```.git``` subdirectory in the current working directory, which contains all of the necessary Git metadata for the new repository. This metadata includes subdirectories for objects, refs, and template files. A HEAD file is also created which points to the currently checked out commit.\n",
    "\n",
    "When you store your data and models in the remote repository, a ```<filename>.dvc``` file is created. A ```<filename>.dvc``` is a small text file that points to your actual data files in remote storage. It is lightweight and meant to be stored with your code in GitHub. When you download a Git repository, you also get the ```<filename>.dvc``` files. You can then use those files to get the data associated with that repository."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e52c84c-e623-46a2-bb8f-f220295d3158",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f47ded-3a7d-49f3-be3a-d36d281c0efe",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Installing the requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682be430-206d-4fdf-bce6-bee45792c41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade pip > /dev/null\n",
    "# !pip install dvc scikit-learn scikit-image pandas numpy > /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0459e99-3d9e-4bc0-9232-73d0cb09466f",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Code structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fac884-558a-4dfa-9713-fe365f6811e6",
   "metadata": {},
   "source": [
    "Fork [this repository](https://github.com/realpython/data-version-control) and clone it for experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8e1493-e0c5-41bb-8161-461660e6f815",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Action</b>:\n",
    "    Change <b>YOUR-GITHUB-USERNAME</b> in the below cell to your username.\n",
    "</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d59795c-b950-413d-968a-1be1b1d243bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/YOUR-GITHUB-USERNAME/data-version-control.git\n",
    "\n",
    "!cd data-version-control && git remote rm origin\n",
    "!cd data-version-control && git remote add origin git@github.com:YOUR-GITHUB-USERNAME/data-version-control.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19aab816-e676-4a6b-bb14-98ff4a8997ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls data-version-control"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba6d182-bf9b-47f4-947e-3162b28d6e35",
   "metadata": {},
   "source": [
    "```\n",
    "├── data/\n",
    "│   ├── prepared/\n",
    "│   └── raw/\n",
    "│\n",
    "├── metrics/\n",
    "├── model/\n",
    "└── src/\n",
    "    ├── evaluate.py\n",
    "    ├── prepare.py\n",
    "    └── train.py\n",
    "```\n",
    "\n",
    "**src/** is for source code.\n",
    "> **prepare.py** contains code for preparing data for training.  \n",
    "> **train.py** contains code for training a machine learning model.  \n",
    "> **evaluate.py** contains code for evaluating the results of a machine learning model.  \n",
    "\n",
    "data/ is for all versions of the dataset.\n",
    "> **data/raw/** is for data obtained from an external source.  \n",
    "> **data/prepared/** is for data modified internally.  \n",
    "\n",
    "**model/** is for machine learning models.  \n",
    "**data/metrics/** is for tracking the performance metrics of your models.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e99b4b-d125-42c0-9271-fe7bd9e4d1cf",
   "metadata": {},
   "source": [
    "#### Downloading [Imagenette](https://github.com/fastai/imagenette) data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1960c4b-1d09-43d7-9d61-ee806b5cf0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd data-version-control && wget -P ./data/raw/ -nc https://s3.amazonaws.com/fast-ai-imageclas/imagenette2-160.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbabc870-a917-4a8a-af06-91856931304c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd data-version-control && ls ./data/raw/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfa9128-3e71-4233-9b87-b67f10ee6ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd data-version-control && tar xf ./data/raw/imagenette2-160.tgz -C ./data/raw/ \n",
    "!cd data-version-control && ls ./data/raw/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a906da7-db42-4569-8ba9-c8078cd4e10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd data-version-control && ls ./data/raw/imagenette2-160  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af604d42-9336-442e-b105-aefa108ae400",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd data-version-control && mv ./data/raw/imagenette2-160/train/ ./data/raw\n",
    "!cd data-version-control && mv ./data/raw/imagenette2-160/val/ ./data/raw\n",
    "!cd data-version-control && ls ./data/raw/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64abd396-9760-4e92-bb93-9d618a5e3e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd data-version-control && rm -rf ./data/raw/imagenette2-160.tgz ./data/raw/imagenette2-160\n",
    "!cd data-version-control && ls ./data/raw/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacb6beb-ce47-4523-8a22-816d863922ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd data-version-control && ls ./data/raw/train/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d698fa3-d6f7-44c4-87c9-4dbfeac8885a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd data-version-control && ls ./data/raw/val/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bd26cb-58c5-42f9-9c61-190fdc6bdc69",
   "metadata": {},
   "source": [
    "Each of the train and val subsets of Imagenette dataset contains 10 classes distribted among 10 different folders correspondingly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c68c51-6948-488a-a7f1-4c1befddab2f",
   "metadata": {},
   "source": [
    "#### Start experimenting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb30df3-2789-4517-93e3-a4e2e87cd2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd data-version-control && git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5538c8c3-d91b-44bb-80ce-d61e07ec035a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new branch.\n",
    "!cd data-version-control && git checkout -b \"first_experiment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7ecb9b-f5a5-4229-80b4-33dafc2e73c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize DVC.\n",
    "!cd data-version-control && dvc init"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04383b89-5d22-4b05-a258-98594539aa9a",
   "metadata": {},
   "source": [
    "This will create a ```.dvc``` folder that holds configuration information, just like the ```.git``` folder for Git."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7b04a7-babd-4bad-a254-7f770ff0b548",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -la data-version-control"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1f022f-74c2-44b9-9291-fa21f70342d3",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "Git gives you the ability to push your local code to a remote repository so that you have a single source of truth shared with other developers. Other people can check out your code and work on it locally without fear of corrupting the code for everyone else. The same is true for DVC. You need some kind of remote storage for the data and model files controlled by DVC. This can be as simple as another folder on your system.\n",
    "</div>\n",
    "\n",
    "Create a folder somewhere on your system outside the `data-version-control/` repository and call it `dvc_remote`. Now come back to your `data-version-control/` repository and tell DVC where the remote storage is on your system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9158182-40c7-4065-b97a-f0548d776a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir dvc_remote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02212e5c-9506-4b07-a539-9e9463c9978b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd data-version-control && dvc remote add -d remote_storage ../dvc_remote/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a195f66e-fe35-43d8-8742-07d4b217eb1d",
   "metadata": {},
   "source": [
    "DVC now knows where to back up your data and models. `dvc remote add` stores the location to your remote storage and names it `remote_storage`. You can choose another name if you want. The `-d` switch tells DVC that this is your default remote storage. You can add more than one storage location and switch between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87954494-f1f7-4d45-b4b7-da96c526f486",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd data-version-control && cat .dvc/config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cab7e5-4a33-49fb-b917-1e7e109009c3",
   "metadata": {},
   "source": [
    "DVC supports many cloud-based storage systems, such as **AWS S3 buckets**, **Google Cloud Storage**, and **Microsoft Azure Blob Storage**. You can find out more in the official DVC documentation for the [dvc remote add](https://dvc.org/doc/command-reference/remote/add) command."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c92e082-2b68-4b6c-9c6e-edc037c9fb95",
   "metadata": {
    "tags": []
   },
   "source": [
    "## DVC in action."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44102f71-1f83-4f09-bb60-c33ba7bebe52",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "Rule of thumb – <b>small files go to GitHub, and large files go to DVC remote storage</b>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a5d24a-a03c-4ab6-83aa-820765a8dc60",
   "metadata": {},
   "source": [
    "Like git, DVC also uses the `add` command to start tracking files. This puts the files under their respective control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7d91e7-a0b3-4eb8-aa89-48150bcd82e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd data-version-control && dvc add -q ./data/raw/train\n",
    "!cd data-version-control && dvc add -q ./data/raw/val "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65fd361-c8df-4e09-88f8-54113c979794",
   "metadata": {},
   "source": [
    "Images are considered large files, especially if they’re collected into datasets with hundreds or thousands of files. **The `add` command adds these two folders under DVC control**. Here’s what DVC does under the hood:\n",
    "\n",
    "- 1) Adds your `train/` and `val/` folders to `.gitignore`\n",
    "- 2) Creates two files with the `.dvc` extension, `train.dvc` and `val.dvc`\n",
    "- 3) Copies the `train/` and `val/` folders to a staging area\n",
    "\n",
    "> `.gitignore` is a text file that has a list of files that Git should ignore, or not track. When a file is listed in `.gitignore`, it’s invisible to git commands. By adding the `train/` and `val/` folders to `.gitignore`, DVC makes sure you won’t accidentally upload large data files to GitHub.\n",
    "\n",
    "> `.dvc` files are small text files that point DVC to your data in remote storage. Remember the rule of thumb: large data files and folders go into DVC remote storage, but the small `.dvc` files go into GitHub. When you come back to your work and check out all the code from GitHub, you’ll also get the `.dvc` files, which you can use to get your large data files.\n",
    "\n",
    "> Finally, DVC copies the data files to a staging area. The staging area is called a **cache**. When you initialized DVC with `dvc init`, it created a `.dvc` folder in your repository. In that folder, it created the cache folder, `.dvc/cache`. When you run `dvc add`, all the files are copied to `.dvc/cache`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc787c1-42e9-45ef-9b85-39c69be7567a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd data-version-control && ls ./data/raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa829338-4def-4011-8441-c338ba8b06c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd data-version-control && cat ./data/raw/train.dvc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb8c6aa-04b2-4045-ad14-43bcc8877c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd data-version-control && ls .dvc/cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d464ac79-9bb1-47ba-9c24-cb25faacb9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once the large image files have been put under DVC control, we can add all \n",
    "# the code and small files to Git control with git add:\n",
    "!cd data-version-control && git add --all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3256aa3e-0dd1-40ea-96f4-c0edc7691a53",
   "metadata": {},
   "source": [
    "<center><img src=\"images/dvc_state_1.png\" width=\"400\" height=\"20\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d9b18a-cec0-4d98-928b-881ee5d9c0b8",
   "metadata": {},
   "source": [
    "If someone wants to work on your project and use the `train/` and `val/` data, then they would first need to download your Git repository. They could then use the `.dvc` files to get the data.\n",
    "\n",
    "**But before people can get your repository and data, you need to upload your files to remote storage.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129c0b3d-2a2a-4ba4-8aa9-562d2c91ab5c",
   "metadata": {},
   "source": [
    "## Uploading files to remote repository"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76ec61a-c37e-4dfb-8e2e-45dab657fc84",
   "metadata": {},
   "source": [
    "To upload files to GitHub, you first need to create a snapshot of the current state of your repository. When you add all the modified files to the staging area with `git add`, create a snapshot with the `commit` command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac3c975-3616-4cad-a254-51c696f1ab94",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd data-version-control && git commit -m \"first commit\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf4fbbc-5d6d-4bd8-b33d-df8e1206f3e2",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "DVC also has a <b>commit</b> command, but it doesn’t do the same thing as <b>git commit</b>. DVC doesn’t need a snapshot of the whole repository. It can just upload individual files as soon as they’re tracked with <b>dvc add</b>.\n",
    "\n",
    "You use <b>dvc commit</b> when an already tracked file changes. If you make a local change to the data, then you would commit the change to the cache before uploading it to remote. You haven’t changed your data since it was added, so you can skip the commit step.\n",
    "</div>\n",
    "\n",
    "To upload files from **cache** to **remote** use the `push` command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b9e2a1-e2c6-4ef1-bc86-bb3e238301d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd data-version-control && dvc push"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc233c4c-2938-438d-aaf7-cae95ee64c0d",
   "metadata": {},
   "source": [
    "Your data is now safely stored in a location away from your repository. Finally, push the files under Git control to GitHub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369a28ef-7fc0-43b0-a489-c4967f6b9302",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd data-version-control && git push --set-upstream origin first_experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d437fe8-2272-4a84-903d-2439e7789681",
   "metadata": {},
   "source": [
    "<center><img src=\"images/dvc_state_2.png\" width=\"400\" height=\"20\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb47c4ec-399a-45bf-89bf-ea20fa4e8cb2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Downloading files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5d7309-3a2d-4069-876a-18bd6a59b672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove a data file.\n",
    "!cd data-version-control && rm -rf data/raw/val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6b494f-d069-4b1b-b647-bed02c0343f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd data-version-control && ls data/raw/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd1e558-233d-45cb-a6a3-67051eb17193",
   "metadata": {},
   "source": [
    "The above command deletes the `data/raw/val/` folder from your repository, but the folder is still safely stored in your cache and the remote storage. You can get it back at any time.\n",
    "\n",
    "**To get your data back from the cache, use the `dvc checkout` command:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25af80a3-ed5d-49b3-8b9f-0c5f49475848",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd data-version-control && dvc checkout data/raw/val.dvc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bf0f9c-5533-4dc0-a3bd-7dd165e9d3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd data-version-control && ls data/raw/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8381493-4791-496b-8d98-6fd5ac170911",
   "metadata": {},
   "source": [
    "> If you want DVC to search through your whole repository and check out everything that’s missing, then use `dvc checkout` with no additional arguments.\n",
    "\n",
    "> When you clone your GitHub repository on a new machine, the cache will be empty. The fetch command gets the contents of the remote storage into the cache, `dvc fetch data/raw/val.dvc`.\n",
    "\n",
    "> Or you can use just `dvc fetch` to get the data for all DVC files in the repository. Once the data is in your cache, check it out to the repository with `dvc checkout`. You can perform both fetch and checkout with a single command, `dvc pull`. It executes `dvc fetch` followed by `dvc checkout`. It copies your data from the remote to the cache and into your repository in a single sweep. These commands roughly mimic what Git does, since Git also has `fetch`, `checkout`, and `pull` commands."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda4eda9-b600-4524-8c05-f27362c741d6",
   "metadata": {},
   "source": [
    "## ML comes into the play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf243b45-44e1-4c16-ab74-5eb3eff4ed53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d04e51-1d5a-496e-a987-b8a2eb5a88ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create csv files for storing filenames and corresponding labels for binary classifcation.\n",
    "!cd data-version-control && python src/prepare.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591e6011-b56d-4593-acd3-e09b99a271b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd data-version-control && ls data/prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f0c06b-7ec9-4980-a6cc-1f68ade9e7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv(\"data-version-control/data/prepared/train.csv\", index_col=0)\n",
    "train_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c430ee6-2b1a-4d41-b3d4-2ec52e7f0af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classes.\n",
    "train_csv.label.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a8d4d7-221a-48d7-9081-23bbaa603ae0",
   "metadata": {},
   "source": [
    "Now we need to add these `train.csv` and `val.csv` files to DVC and the corresponding `.dvc` files to GitHub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2e3918-2f9e-4718-81b8-479bef14fd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd data-version-control && dvc add -q data/prepared/train.csv data/prepared/test.csv\n",
    "!cd data-version-control && git add --all\n",
    "!cd data-version-control && git commit -m \"Created train and test CSV files\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1966bda7-ae86-4381-9219-93f85084f908",
   "metadata": {},
   "source": [
    "Training SVM classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d2ed79-754d-4215-a8f4-af5c6def858f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd data-version-control && python src/train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ee2a8d-cdd7-478b-97d0-c8b1a0700bae",
   "metadata": {},
   "source": [
    "When the script finishes, you’ll have a trained machine learning model saved in the `model/` folder with the name `model.joblib`. This is the most important file of the experiment. It needs to be added to DVC, with the corresponding `.dvc` file committed to GitHub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302621b1-f1dc-48dd-afd8-97de7bce58c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd data-version-control && ls model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fee3220-7d67-4cc6-94be-a35244ca34e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd data-version-control && dvc add -q model/model.joblib\n",
    "!cd data-version-control && git add --all\n",
    "!cd data-version-control && git commit -m \"svm classifier\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce691f5-4e44-4585-b692-8cd18cd1620a",
   "metadata": {},
   "source": [
    "Let's evaluate our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b49b2b-ec40-49e1-b417-f644f0ff98e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd data-version-control && python src/evaluate.py\n",
    "!cd data-version-control && cat metrics/accuracy.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18acf969-ef2f-45a1-8b88-41d7aa27ca46",
   "metadata": {},
   "source": [
    "As accuracy JSON file is really small, and it’s useful to keep it in GitHub so you can quickly check how well each experiment performed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb64f32c-a0bd-4af9-b7f4-5dddda34e339",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd data-version-control && git add --all\n",
    "!cd data-version-control && git commit -m \"evaluated SVM accuracy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c51c0a8-9a57-4445-821b-b2d98c327de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd data-version-control && git push\n",
    "!cd data-version-control && dvc push"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cec23cb-32f3-432c-a888-67a62e6d3e73",
   "metadata": {},
   "source": [
    "## Version Datasets and Models (advanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da5bb7f-a463-4341-904b-d2b392d1ad7a",
   "metadata": {},
   "source": [
    "A common practice is to use tagging to mark a specific point in your Git history as being important. Since you’ve completed an experiment and produced a new model, create a tag to signal to yourself and others that you have a ready-to-go model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f343da2c-bdca-4a61-932a-b78b600440ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd data-version-control && git tag -a svm-classifier -m \"SVM classifier with accuracy 64%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa66945-c535-42d7-b784-d328a9f2cb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Git tags aren’t pushed with regular commits, so they have to be pushed separately to \n",
    "# your repository’s origin on GitHub or whatever platform you use. Use the --tags switch \n",
    "# to push all tags from your local repository to the remote:\n",
    "\n",
    "!cd data-version-control && git push origin --tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dea2f18-4d7d-4b9a-9bea-89ca2f65efae",
   "metadata": {},
   "source": [
    "A common practice is to create a new branch for every single experiment. Let's increase the number of iterations and observe if there is improvement in classificaion accuracy or not.\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Action</b>:\n",
    "    Modify your train.py to increase the number of iterations to 100.\n",
    "</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e188b61d-7464-4f18-bdfe-c0690a5432de",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd data-version-control && git checkout -b \"svm-100-iterations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405ee4f7-a19f-46f6-8242-f3bf9a340109",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd data-version-control && python src/train.py\n",
    "!cd data-version-control && python src/evaluate.py\n",
    "!cd data-version-control && cat metrics/accuracy.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3ceb27-042c-4afb-95cc-28de3e1dd900",
   "metadata": {},
   "source": [
    "Now since the training process has changed the *model.joblib* file, you need to commit it to the DVC cache.\n",
    "\n",
    "Remember, `dvc commit` works differently from `git commit` and is used to update an already tracked file. This won’t delete the previous model, but it will create a new one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8aa3d6d-a9d0-47e4-baf9-ba45ac71f71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd data-version-control && dvc commit -f  # --force\n",
    "# Normally, this will ask you if you are sure you want to make the change, click on 'Y' for Yes. To escape\n",
    "# from doing that in jupyter notebook, use -f or --force. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab00c42-971c-4364-82b2-5643c8e69bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add and commit the changes you’ve made to Git:\n",
    "!cd data-version-control && git add --all\n",
    "!cd data-version-control && git commit -m \"change svm max_iter to 100\"\n",
    "\n",
    "# Tag the new experiment:\n",
    "!cd data-version-control && git tag -a svm-100-iter -m \"trained an svm classifier for 100 iterations\"\n",
    "!cd data-version-control && git push origin --tags\n",
    "\n",
    "# Push the code changes to GitHub and the DVC changes to the remote storage:\n",
    "!cd data-version-control && git push --set-upstream origin svm-100-iter\n",
    "!cd data-version-control && dvc push"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1066dbf9-6dc3-44f2-85d0-d5e84ee652e8",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "We can now jump between branches <b>first_experiment</b> and <b>svm-100-iterations</b> by checking out the code from GitHub and then checking out the data and model from DVC:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60c04eb-9222-4d20-a6d4-e7060e61f9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd data-version-control && git checkout first_experiment\n",
    "!cd data-version-control && dvc checkout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cefa27f-f720-4cd6-9079-abae14d054fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's evaluate.\n",
    "!cd data-version-control && python src/evaluate.py\n",
    "!cd data-version-control && cat metrics/accuracy.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c601deec-e099-4c9b-ba18-89ac985d4651",
   "metadata": {},
   "source": [
    "I have already seen this number 😃"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ac0159-cf79-46c9-9012-27eae3e0131d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "What we learnt so far is to conduct an experiment, store the corresponding model weights and data associated with it and then conduct another experiment keeping the possibility to always go back and reproduce the results from the previous experiment.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529507c6-32d2-452e-a4db-bf2945309e61",
   "metadata": {},
   "source": [
    "## Creating Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d317721-7fbf-4455-8ad5-830d2f482ee0",
   "metadata": {},
   "source": [
    "So far we have fetched the data manually and added it to remote storage. You can now get it with `dvc checkout` or `dvc pull`. The other steps were executed by running various Python files. These can be chained together into a single execution called a **DVC pipeline** that requires only one command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12955827-8fe8-4592-9cbf-566040fd477b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new branch:\n",
    "!cd data-version-control && git checkout -b svm-pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f746b3-e41f-4bfd-8e78-5ba82dd2d7b0",
   "metadata": {},
   "source": [
    " A pipeline consists of multiple stages and is executed using a `dvc run` command. Each stage has three components:\n",
    "- Inputs – pipeline inputs, DVC term **dependencies**\n",
    "- Outputs – pipeline outputs, DVC term **outs**\n",
    "- Command – anything you usually run in the command line, including Python files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56174eb-5e25-4d39-8eb4-86fb4a19a01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will remove the .dvc files and the associated data targeted by the .dvc files. \n",
    "# We should now have a blank slate to re-create these files using DVC pipelines.\n",
    "!cd data-version-control && dvc remove data/prepared/train.csv.dvc \\\n",
    "                                        data/prepared/test.csv.dvc \\\n",
    "                                        model/model.joblib.dvc --outs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e8e95c-08a9-4f80-985c-ba55213b4452",
   "metadata": {},
   "source": [
    "First, you’re going to run `prepare.py` as a DVC pipeline stage. The command for this is `dvc run`, which needs to know the dependencies, outputs, and command:  \n",
    "\n",
    "- Dependencies: `prepare.py` and the data in `data/raw`  \n",
    "- Outputs: `train.csv` and `test.csv`  \n",
    "- Command: `python prepare.py`  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1044c9-7720-42b7-9825-8e820333a704",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd data-version-control && dvc run -n prepare \\\n",
    "                                -d src/prepare.py -d data/raw \\\n",
    "                                -o data/prepared/train.csv -o data/prepared/test.csv \\\n",
    "                                python src/prepare.py\n",
    "\n",
    "# -n switch gives the stage a name.\n",
    "# -d switch passes the dependencies to the command.\n",
    "# -o switch defines the outputs of the command."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44713cf3-19b3-4fc3-a003-9efffa2d362a",
   "metadata": {},
   "source": [
    "Once you create the stage, DVC will create two files, `dvc.yaml` and `dvc.lock`. let's check them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c3eabc-c4cb-4f84-8c96-34ad9fb80ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd data-version-control && cat dvc.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cf9201-6804-43d5-aaae-db5fa0ebb811",
   "metadata": {},
   "source": [
    "The top-level element, stages, has elements nested under it, one for each stage. Currently, we have only one stage, prepare. As we chain more, they’ll show up in this file. Technically, we don’t have to type `dvc run` commands in the command line—you can create all your stages here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c103c6-b9a5-45ba-bffd-68d8920511f9",
   "metadata": {},
   "source": [
    "<center><img src=\"images/new-pipeline_1.png\" width=\"400\" height=\"20\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bd9ca9-d7ab-4f6e-bc44-7cc00fae8e22",
   "metadata": {},
   "source": [
    "The next stage in the pipeline is training. The dependencies are the `train.py` file itself and the `train.csv` file in `data/prepared`. The only output is the `model.joblib` file. To create a pipeline stage out of `train.py`, execute it with `dvc run`, specifying the correct dependencies and outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d00ae97-444c-45f8-b949-484c3e1083a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd data-version-control && dvc run -n train \\\n",
    "                                    -d src/train.py -d data/prepared/train.csv \\\n",
    "                                    -o model/model.joblib \\\n",
    "                                    python src/train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0799c80-01b2-440e-b650-1a0fd3009b0d",
   "metadata": {},
   "source": [
    "The final stage will be the evaluation. The dependencies are the `evaluate.py` file and the model file generated in the previous stage. The output is the metrics file, `accuracy.json`. Execute `evaluate.py` with `dvc run`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ee74a0-b0a3-4499-a12e-7187fb6e3b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd data-version-control && dvc run -n evaluate \\\n",
    "                                    -d src/evaluate.py -d model/model.joblib \\\n",
    "                                    -M metrics/accuracy.json \\\n",
    "                                    python src/evaluate.py\n",
    "\n",
    "# Notice that we used the -M switch instead of -o. DVC treats metrics differently from other outputs. \n",
    "# When you run this command, it will generate the accuracy.json file, but DVC will know that it’s a \n",
    "# metric used to measure the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f44e66-9ecd-4b47-9b05-393a658a46ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can get DVC to show you all the metrics it knows about with the dvc show command:\n",
    "!cd data-version-control && dvc metrics show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5174c5b-fc42-4028-9a54-93b4db62d1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd data-version-control && cat dvc.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a50d1f3-cee0-424b-b649-e7ce3acdd464",
   "metadata": {},
   "source": [
    "<center><img src=\"images/new-pipeline_final.png\" width=\"1100\" height=\"100\"/></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8dd482-df9d-457b-8911-61db7d2d912d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version and store your code, models, and data for the new DVC pipeline:\n",
    "!cd data-version-control && git add --all\n",
    "!cd data-version-control && git commit -m \"rerun svm as pipeline\"\n",
    "!cd data-version-control && dvc commit\n",
    "!cd data-version-control && git push --set-upstream origin svm-pipeline\n",
    "!cd data-version-control && git tag -a svm-pipeline -m \"trained svm as DVC pipeline.\"\n",
    "!cd data-version-control && git push origin --tags\n",
    "!cd data-version-control && dvc push"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fba687-f011-490a-8d89-ee7da4b56c7c",
   "metadata": {},
   "source": [
    "### Now let's change the model while reusing the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d139ac-5909-4d58-b212-be06c7bb7a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd data-version-control && git checkout -b \"random_forest\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eaf24bd-2eda-4eb0-a9f7-0cc5bf6f3c14",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Action</b>:\n",
    "    Modify your train.py to use a RandomForestClassifier.\n",
    "</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115d64e1-b7c4-47d1-9c59-908be0af6c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all the changed dependencies for every stage of the pipeline:\n",
    "!cd data-version-control && dvc status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dea6059-cdfe-41bd-af59-2161bbb00712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the change in the model will affect the metric as well, you want to reproduce the whole chain. \n",
    "# You can reproduce any DVC pipeline file with the `dvc repro` command:\n",
    "!cd data-version-control && dvc repro evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b470f4-412c-4126-afe2-d9b6e4a76bc4",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "And that’s it! When you run the `repro` command, DVC checks all the dependencies of the entire pipeline to determine what’s changed and which commands need to be executed again. Think about what this means. You can jump from branch to branch and reproduce any experiment with a single command!\n",
    "</div>\n",
    "\n",
    "**DVC reruns only the changed parts of the pipeline. If you noticed above, *skipping* means that DVC skips the corresponding steps regarding data as it wasn't changed.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755839a3-84b9-4888-9434-4900cfab5c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd data-version-control && cat metrics/accuracy.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa9198e-1d37-439b-9e33-2aaf24bd4c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd data-version-control && git add --all\n",
    "!cd data-version-control && git commit -m \"train Random Forrest classifier\"\n",
    "!cd data-version-control && dvc commit\n",
    "!cd data-version-control && git push --set-upstream origin random-forest\n",
    "!cd data-version-control && git tag -a random-forest -m \"Random Forest classifier\"\n",
    "!cd data-version-control && git push origin --tags\n",
    "!cd data-version-control && dvc push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632f9d8b-047a-43ee-b7d0-054b5f9e955d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare metrics across multiple tags:\n",
    "!cd data-version-control && dvc metrics show -T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa9a5f6-4dab-4521-8d60-961aa2b93505",
   "metadata": {},
   "source": [
    "When you come back to this project after several months and don’t remember the details, you can check which setup was the most successful with `dvc metrics show -T` and reproduce it with `dvc repro`! Anyone else who wants to reproduce your work can do the same. They’ll just need to take three steps:\n",
    "- Run `git clone` or `git checkout` to get the code and `.dvc` files.\n",
    "- Get the training data with `dvc checkout`.\n",
    "- Reproduce the entire workflow with `dvc repro evaluate`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4852a9cc-6176-4550-bb74-8ba3a14e9799",
   "metadata": {},
   "source": [
    "<center><img src=\"images/thank_you.jpeg\" width=\"300\" height=\"500\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32eb2e02-1bf1-4a05-9aac-458699479e64",
   "metadata": {},
   "source": [
    "## References\n",
    "- [Data Version Control With Python and DVC](https://realpython.com/python-data-version-control/)\n",
    "- [Tutorial: Data and Model Versioning](https://dvc.org/doc/use-cases/versioning-data-and-models/tutorial)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_mlops",
   "language": "python",
   "name": "env_mlops"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
