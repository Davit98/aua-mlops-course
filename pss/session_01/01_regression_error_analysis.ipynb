{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0257b7c-2246-46cf-ac55-dd8f0f2035b2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# AUA, DS 229 – MLOps\n",
    "### Week 2 – Responsible Machine Learning with Error Analysis\n",
    "\n",
    "- [Responsible Machine Learning with Error Analysis](https://techcommunity.microsoft.com/t5/ai-machine-learning-blog/responsible-machine-learning-with-error-analysis/ba-p/2141774)\n",
    "- [Responsible AI dashboard: A one-stop shop for operationalizing Responsible AI in practice](https://techcommunity.microsoft.com/t5/ai-machine-learning-blog/responsible-ai-dashboard-a-one-stop-shop-for-operationalizing/ba-p/3030944)\n",
    "- [AI Show: Live Responsible AI Dashboard: One-stop shop for operationalizing RAI in practice](https://techcommunity.microsoft.com/t5/video-hub/ai-show-live-responsible-ai-dashboard-one-stop-shop-for/ba-p/3060153)\n",
    "- [Getting started](https://github.com/microsoft/responsible-ai-toolbox/blob/main/notebooks/responsibleaidashboard/getting-started.ipynb)\n",
    "- [Take a Tour: Responsible AI Toolbox](https://github.com/microsoft/responsible-ai-toolbox/blob/main/notebooks/responsibleaidashboard/tour.ipynb)\n",
    "\n",
    "# Notebook 01 – Regression Error Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6550b0",
   "metadata": {},
   "source": [
    "This notebook demonstrates the use of the Responsible AI Toolbox to make error analysis for regressn task. It walks through the API calls necessary to create a widget that guides a visual analysis of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafcf76e-b4a2-4757-a44a-331710de6e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade pip\n",
    "# !pip install interpret-community \n",
    "# !pip install raiwidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20f25c3",
   "metadata": {},
   "source": [
    "## Launch Responsible AI Toolbox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a122e129",
   "metadata": {},
   "source": [
    "The following section examines the code necessary to create the dataset. It then generates insights using the `responsibleai` API that can be visually analyzed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebae7586",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927997ce",
   "metadata": {},
   "source": [
    "First, load the apartment dataset and specify the different types of features. Then, clean it and put it into a DataFrame with named columns. After loading and cleaning the data, split the datapoints into training and test sets. Assemble separate datasets for the full sample and the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f4447e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from raiutils.dataset import fetch_dataset\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "def split_label(dataset, target_feature):\n",
    "    X = dataset.drop([target_feature], axis=1)\n",
    "    y = dataset[[target_feature]]\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def clean_data(X, y, target_feature):\n",
    "    features = X.columns.values.tolist()\n",
    "    classes = y[target_feature].unique().tolist()\n",
    "    pipe_cfg = {\n",
    "        'num_cols': X.dtypes[X.dtypes == 'int64'].index.values.tolist(),\n",
    "        'cat_cols': X.dtypes[X.dtypes == 'object'].index.values.tolist(),\n",
    "    }\n",
    "    num_pipe = Pipeline([\n",
    "        ('num_imputer', SimpleImputer(strategy='median')),\n",
    "        ('num_scaler', StandardScaler())\n",
    "    ])\n",
    "    cat_pipe = Pipeline([\n",
    "        ('cat_imputer', SimpleImputer(strategy='constant', fill_value='?')),\n",
    "        ('cat_encoder', OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
    "    ])\n",
    "    feat_pipe = ColumnTransformer([\n",
    "        ('num_pipe', num_pipe, pipe_cfg['num_cols']),\n",
    "        ('cat_pipe', cat_pipe, pipe_cfg['cat_cols'])\n",
    "    ])\n",
    "    X = feat_pipe.fit_transform(X)\n",
    "    \n",
    "    print(\"Categorical columns:\", pipe_cfg['cat_cols'])\n",
    "    print(\"Numerical columns:\", pipe_cfg['num_cols'])\n",
    "    return X, feat_pipe, features, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281d6f66-0782-4c45-8905-624347453138",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_feature = 'SalePriceK'\n",
    "categorical_features = []\n",
    "\n",
    "outdirname = 'responsibleai.12.28.21'\n",
    "zipfilename = outdirname + '.zip'\n",
    "\n",
    "fetch_dataset('https://publictestdatasets.blob.core.windows.net/data/' + zipfilename, zipfilename)\n",
    "\n",
    "with zipfile.ZipFile(zipfilename, 'r') as unzip:\n",
    "    unzip.extractall('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092fefc2-4fd9-4e9d-9f49-d765833dd6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Reading the data and splitting into train/test.\n",
    "all_data = pd.read_csv('apartments-train.csv')\n",
    "all_data = all_data.drop(['Sold_HigherThan_Median','SalePrice'], axis=1)\n",
    "X, y = split_label(all_data, target_feature)\n",
    "X_train_original, X_test_original, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=7)\n",
    "\n",
    "# 2) Preprocessing train/test parts (median imputation and standard scaling of numerical columsn, \n",
    "#    constan imputation and one-hot encoding of categorical features). \n",
    "X_train, feat_pipe, features, classes = clean_data(X_train_original, y_train, target_feature)\n",
    "y_train = y_train[target_feature].to_numpy()\n",
    "X_test = feat_pipe.transform(X_test_original)\n",
    "y_test = y_test[target_feature].to_numpy()\n",
    "\n",
    "# 3) Train/test dataframe construction.\n",
    "train_data = X_train_original.copy()\n",
    "train_data[target_feature] = y_train\n",
    "test_data = X_test_original.copy()\n",
    "test_data[target_feature] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972c558d-354c-4280-a06f-a1df18700b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e3860a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create Data Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345bc680-952a-4e4c-8b53-f7801fe77e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf07eef-bf10-459a-bbd9-02815c0583ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Train data shape: {train_data.shape}\")\n",
    "print(f\"Test data shape: {test_data.shape}\")\n",
    "print(f\"Target: {target_feature}\")\n",
    "\n",
    "sns.displot(data=train_data, x=target_feature)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6d681e-354a-4696-b036-e43f14076a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ignore_target(df):\n",
    "    \"\"\"Selects all columns but target.\"\"\"\n",
    "    return df.loc[:, df.columns != target_feature]\n",
    "\n",
    "\n",
    "# Fitting a Random Forest Regressor model.\n",
    "model = RandomForestRegressor().fit(X=ignore_target(train_data), y=train_data[target_feature])\n",
    "y_pred = model.predict(ignore_target(test_data))\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = model.score(ignore_target(test_data), y_test)\n",
    "print(f\"MSE: {round(mse, 2)}\\nMAE: {round(mae, 2)}\\nR^2: {round(r2, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516b2fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from raiwidgets import ResponsibleAIDashboard\n",
    "from responsibleai import RAIInsights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8b0634",
   "metadata": {},
   "source": [
    "To use Responsible AI Dashboard, initialize a RAIInsights object upon which different components can be loaded.\n",
    "\n",
    "RAIInsights accepts the model, the full dataset, the test dataset, the target feature string, the task type string, and a list of strings of categorical feature names as its arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c941835b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rai_insights = RAIInsights(model, train_data, test_data, target_feature, 'regression',\n",
    "                           categorical_features=categorical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec82a856",
   "metadata": {},
   "source": [
    "Once all the desired components have been loaded, compute insights on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b179d7-27db-4632-9fc9-e6a9b98d9560",
   "metadata": {},
   "outputs": [],
   "source": [
    "rai_insights.explainer.add()  # Interpretability.\n",
    "rai_insights.error_analysis.add()  # Error Analysis.\n",
    "rai_insights.causal.add(treatment_features=['OverallCond', 'OverallQual', 'Fireplaces', 'GarageCars', \n",
    "                                            'ScreenPorch'])  # Causal insights.\n",
    "\n",
    "rai_insights.compute()  # Compute insights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b5112c",
   "metadata": {},
   "source": [
    "Finally, visualize and explore the model insights. Use the resulting widget or follow the link to view this in a new tab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73ad853",
   "metadata": {},
   "outputs": [],
   "source": [
    "ResponsibleAIDashboard(rai_insights, port=6009)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3f55f5-72d2-43c4-bcaf-94705c23af10",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### **Tasks:**\n",
    "<div class=\"alert alert-success\">\n",
    "\n",
    "✅ Investigate **Error analysis** tab:\n",
    "  - Chart **Tree map** is used to identify common failure patterns (notice that MAE is significantly higher for *GrLivArea > 2671*).\n",
    "  - Chart **Heat map** is sued to focus on combination of features (visualize 'GrLivArea' vs 'YearBuilt', what can you infer?).\n",
    "    \n",
    "✅ Investigate **Model overview** tab:\n",
    "  - Chart **Dataset cohorts** is used to analyze your model performance on different dataset cohorts.\n",
    "  - Chart **Feature cohorts** is used to do a comparative analysis across sensitive groups (analyze 'YearBuilt' and derive insights).\n",
    "\n",
    "✅ Investigate **Data Anlysis** tab:\n",
    "  - Chart **Table view** is used to analyze dataset with predictions.    \n",
    "  - Chart **Chart view** is used to analyze dataset statistics across differend groups:    \n",
    "      - Use **Individual datapoints** subsection to construct 2D plots, e.g. construct 'Predicted Y' vs 'True Y' plot.\n",
    "      - Use **Aggregate plots** subsection to visualize against different attributes, e.g. 'Error' vs 'YearBuilt' and 'GrLivArea'. \n",
    "    \n",
    "✅ Investigate **Feature importances** tab:\n",
    "  - Chart **Aggregate feature importance** is used to visualize top-k decisive features.\n",
    "  - Chart **Individual feature importance** is used for more granular analysis:\n",
    "      - Use **Feature importance plot** to select up to 5 datapoints and visualize which features were important for those particular predictions. Note that this can be valuable for fairness analysis, imagine that features like neighborhood, gender, skin color appear to be critical for your model, is there any problem?\n",
    "      - Use **Individual conditional expectation (ICE) plot** to investigate how changing a feature value from a minimum value to a maximum value impacts the prediction on the selected data instance. Derive insights for 'YearBuilt' and 'GrLivArea'.\n",
    "    \n",
    "✅ Investigate **Causal analysis** tab:\n",
    "  - Chart **Aggregate causal effects** is used to answer \"what-if\" questions. In particular, for each treatment variable passed to the API you get how much the prediction will change if you increase a variable by one unit.\n",
    "  - Chart **Individual causal what-if** does the same as above for a specific data point.\n",
    "  - Chart **Treatment policy** represents the best future interventions one can apply to his/her houses to see the biggest positive boost in the housing prices. Derive insights for a treatment variable 'ScreenPorch'. Below you can find gains for the suggested policis relative to the baseline of not making any change.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6d610b",
   "metadata": {},
   "source": [
    "See this [developer blog](https://techcommunity.microsoft.com/t5/ai-machine-learning-blog/responsible-ai-dashboard-a-one-stop-shop-for-operationalizing/ba-p/3030944) (Decision Making Flow section) to learn more about this use case and how to use the dashboard to debug your housing price prediction model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c910e7d-3055-4b2a-8d2c-73480879bc98",
   "metadata": {
    "tags": []
   },
   "source": [
    "### References\n",
    "- Responsible AI Toolbox [[Source]](https://github.com/microsoft/responsible-ai-toolbox/blob/main/notebooks/responsibleaidashboard/responsibleaidashboard-housing-decision-making.ipynb) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_mlops",
   "language": "python",
   "name": "env_mlops"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
